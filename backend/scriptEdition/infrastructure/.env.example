# LLM Provider Configuration
LLM_PROVIDER=openai

# Anthropic Configuration
ANTHROPIC_API_KEY=your_anthropic_api_key_here
ANTHROPIC_MODEL=claude-3-5-haiku-20241022
# ANTHROPIC_BASE_URL=https://api.anthropic.com/v1

# OpenAI Configuration (also works with Ollama)
OPENAI_API_KEY=ollama-local-key
OPENAI_MODEL=llama3.2
OPENAI_BASE_URL=http://localhost:11434/v1

# Ollama Configuration (when using direct Ollama provider)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.2

# System Prompt Configuration
# Available options:
# - system-prompt.txt (default - original prompt)
# - system-prompt.mercury.txt (Mercury-Coder optimized prompt)
SYSTEM_PROMPT_FILE=system-prompt.mercury.txt

# Examples for different scenarios:
# For Mercury-Coder: SYSTEM_PROMPT_FILE=system-prompt.mercury.txt
# For Claude/GPT-4: SYSTEM_PROMPT_FILE=system-prompt.txt
# For custom prompt: SYSTEM_PROMPT_FILE=system-prompt.custom.txt
EOF < /dev/null